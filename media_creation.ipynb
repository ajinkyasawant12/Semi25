{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to  crate 3D digital twin form live realtime feed of came"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary dependencies\n",
    "!pip install torch torchvision opencv-python matplotlib open3d numpy ultralytics transformers timm pillow psutil pycolmap\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import time\n",
    "from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
    "import psutil\n",
    "import pycolmap\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load advanced depth estimation model\n",
    "image_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-large\")\n",
    "depth_model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\").to(device)\n",
    "\n",
    "# Function to run PyCOLMAP for camera pose and intrinsic estimation\n",
    "def run_pycolmap(image_folder, workspace_folder):\n",
    "    # Feature extraction\n",
    "    pycolmap.extract_features(database_path=f\"{workspace_folder}/database.db\", image_path=image_folder)\n",
    "    \n",
    "    # Exhaustive matching\n",
    "    pycolmap.match_exhaustive(database_path=f\"{workspace_folder}/database.db\")\n",
    "    \n",
    "    # Sparse reconstruction\n",
    "    sparse_folder = f\"{workspace_folder}/sparse\"\n",
    "    os.makedirs(sparse_folder, exist_ok=True)\n",
    "    pycolmap.mapper(database_path=f\"{workspace_folder}/database.db\", image_path=image_folder, output_path=sparse_folder)\n",
    "    \n",
    "    # Dense reconstruction\n",
    "    dense_folder = f\"{workspace_folder}/dense\"\n",
    "    os.makedirs(dense_folder, exist_ok=True)\n",
    "    pycolmap.undistort_images(image_path=image_folder, input_path=f\"{sparse_folder}/0\", output_path=dense_folder)\n",
    "    pycolmap.patch_match_stereo(workspace_path=dense_folder)\n",
    "    pycolmap.stereo_fusion(workspace_path=dense_folder, output_path=f\"{dense_folder}/fused.ply\")\n",
    "    \n",
    "    # Export model\n",
    "    pycolmap.convert_model(input_path=f\"{sparse_folder}/0\", output_path=workspace_folder, output_type=\"TXT\")\n",
    "\n",
    "# Video to Point Cloud Converter\n",
    "class VideoToTwinConverter:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.depth_model = depth_model\n",
    "        self.image_processor = image_processor\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def _generate_pointcloud(self, rgb, depth):\n",
    "        h, w = depth.shape\n",
    "        fx, fy = 0.8*w, 0.8*h  # Simplified focal length\n",
    "\n",
    "        yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n",
    "        z = depth * 100  # Scale factor\n",
    "        x = (xx - w/2) * z / fx\n",
    "        y = (yy - h/2) * z / fy\n",
    "\n",
    "        points = np.vstack((x.ravel(), y.ravel(), z.ravel())).T\n",
    "        colors = rgb.reshape(-1, 3)/255.0\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        return pcd\n",
    "\n",
    "    def process_frames(self, frames):\n",
    "        # Preprocess frames\n",
    "        inputs = self.image_processor(images=frames, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        # Depth prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.depth_model(**inputs)\n",
    "            depths = outputs.predicted_depth.squeeze().cpu().numpy()\n",
    "\n",
    "        # Generate point clouds\n",
    "        pointclouds = [self._generate_pointcloud(frames[i], depths[i]) for i in range(len(frames))]\n",
    "        return pointclouds\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize components\n",
    "    converter = VideoToTwinConverter(batch_size=32)\n",
    "\n",
    "    # Open the video file\n",
    "    video_path = '/path/to/your/video.mp4'  # Update this path to your video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frames = []\n",
    "    image_folder = './datafiles/custom/JPEGImages/640p/custom'\n",
    "    workspace_folder = './datafiles/custom/triangulation'\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    os.makedirs(workspace_folder, exist_ok=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frames.append(frame)\n",
    "        frame_path = os.path.join(image_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "        # Process frames in batches\n",
    "        if len(frames) == converter.batch_size:\n",
    "            pointclouds = converter.process_frames(frames)\n",
    "            frames = []\n",
    "\n",
    "            # Save point clouds to files\n",
    "            for i, pcd in enumerate(pointclouds):\n",
    "                o3d.io.write_point_cloud(f\"pointcloud_{frame_count - len(pointclouds) + i:04d}.ply\", pcd)\n",
    "\n",
    "            # Monitor system and GPU memory usage\n",
    "            system_memory = psutil.virtual_memory()\n",
    "            gpu_memory = torch.cuda.memory_allocated()\n",
    "            print(f\"System Memory Usage: {system_memory.percent}%\")\n",
    "            print(f\"GPU Memory Usage: {gpu_memory / (1024 ** 2)} MB\")\n",
    "\n",
    "    # Process remaining frames\n",
    "    if frames:\n",
    "        pointclouds = converter.process_frames(frames)\n",
    "        for i, pcd in enumerate(pointclouds):\n",
    "            o3d.io.write_point_cloud(f\"pointcloud_{frame_count - len(pointclouds) + i:04d}.ply\", pcd)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Run PyCOLMAP to estimate camera pose and intrinsic parameters\n",
    "    run_pycolmap(image_folder, workspace_folder)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total processing time: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Visualize saved point clouds\n",
    "    for i in range(frame_count):\n",
    "        pcd = o3d.io.read_point_cloud(f\"pointcloud_{i:04d}.ply\")\n",
    "        o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
