{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to  crate 3D digital twin form live realtime feed of came"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary dependencies\n",
    "!pip install torch torchvision opencv-python matplotlib open3d numpy ultralytics transformers timm pillow\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from transformers import DPTFeatureExtractor, DPTForDepthEstimation\n",
    "from google.colab import files\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define a simple depth estimation model\n",
    "class DepthEstimator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(64, 128, 3, padding=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 64, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            torch.nn.Conv2d(64, 1, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# Video to Point Cloud Converter\n",
    "class VideoToTwinConverter:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.depth_model = DepthEstimator().to(self.device)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def _generate_pointcloud(self, rgb, depth):\n",
    "        h, w = depth.shape\n",
    "        fx, fy = 0.8*w, 0.8*h  # Simplified focal length\n",
    "\n",
    "        yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n",
    "        z = depth * 100  # Scale factor\n",
    "        x = (xx - w/2) * z / fx\n",
    "        y = (yy - h/2) * z / fy\n",
    "\n",
    "        points = np.vstack((x.ravel(), y.ravel(), z.ravel())).T\n",
    "        colors = rgb.reshape(-1, 3)/255.0\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        return pcd\n",
    "\n",
    "    def process_frames(self, frames):\n",
    "        # Preprocess frames\n",
    "        input_tensors = [self.transform(frame).unsqueeze(0) for frame in frames]\n",
    "        input_tensors = torch.cat(input_tensors).to(self.device)\n",
    "\n",
    "        # Depth prediction\n",
    "        with torch.no_grad():\n",
    "            depths = self.depth_model(input_tensors).squeeze().cpu().numpy()\n",
    "\n",
    "        # Generate point clouds\n",
    "        pointclouds = [self._generate_pointcloud(frames[i], depths[i]) for i in range(len(frames))]\n",
    "        return pointclouds\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize components\n",
    "    converter = VideoToTwinConverter(batch_size=32)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture('/path/to/your/video.mp4')  # Update path\n",
    "\n",
    "    frames = []\n",
    "    start_time = time.time()\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "        # Process frames in batches\n",
    "        if len(frames) == converter.batch_size:\n",
    "            pointclouds = converter.process_frames(frames)\n",
    "            frames = []\n",
    "\n",
    "            # Visualize point clouds using Open3D\n",
    "            for pcd in pointclouds:\n",
    "                o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "            # Monitor system and GPU memory usage\n",
    "            system_memory = psutil.virtual_memory()\n",
    "            gpu_memory = torch.cuda.memory_allocated()\n",
    "            print(f\"System Memory Usage: {system_memory.percent}%\")\n",
    "            print(f\"GPU Memory Usage: {gpu_memory / (1024 ** 2)} MB\")\n",
    "\n",
    "    # Process remaining frames\n",
    "    if frames:\n",
    "        pointclouds = converter.process_frames(frames)\n",
    "        for pcd in pointclouds:\n",
    "            o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    cap.release()\n",
    "    end_time = time.time()\n",
    "    print(f\"Total processing time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
