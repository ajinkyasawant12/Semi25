{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to  crate 3D digital twin form live realtime feed of came"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary dependencies\n",
    "!pip install torch torchvision opencv-python matplotlib open3d numpy ultralytics transformers timm pillow psutil pycolmap\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "import time\n",
    "from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
    "import psutil\n",
    "import pycolmap\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load advanced depth estimation model\n",
    "image_processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-large\")\n",
    "depth_model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\").to(device)\n",
    "\n",
    "# Function to run PyCOLMAP for camera pose and intrinsic estimation\n",
    "def run_pycolmap(image_folder, workspace_folder):\n",
    "    # Feature extraction\n",
    "    pycolmap.extract_features(database_path=f\"{workspace_folder}/database.db\", image_path=image_folder)\n",
    "    \n",
    "    # Exhaustive matching\n",
    "    pycolmap.match_exhaustive(database_path=f\"{workspace_folder}/database.db\")\n",
    "    \n",
    "    # Sparse reconstruction\n",
    "    sparse_folder = f\"{workspace_folder}/sparse\"\n",
    "    os.makedirs(sparse_folder, exist_ok=True)\n",
    "    pycolmap.mapper(database_path=f\"{workspace_folder}/database.db\", image_path=image_folder, output_path=sparse_folder)\n",
    "    \n",
    "    # Dense reconstruction\n",
    "    dense_folder = f\"{workspace_folder}/dense\"\n",
    "    os.makedirs(dense_folder, exist_ok=True)\n",
    "    pycolmap.undistort_images(image_path=image_folder, input_path=f\"{sparse_folder}/0\", output_path=dense_folder)\n",
    "    pycolmap.patch_match_stereo(workspace_path=dense_folder)\n",
    "    pycolmap.stereo_fusion(workspace_path=dense_folder, output_path=f\"{dense_folder}/fused.ply\")\n",
    "    \n",
    "    # Export model\n",
    "    pycolmap.convert_model(input_path=f\"{sparse_folder}/0\", output_path=workspace_folder, output_type=\"TXT\")\n",
    "\n",
    "# Video to Point Cloud Converter\n",
    "class VideoToTwinConverter:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.depth_model = depth_model\n",
    "        self.image_processor = image_processor\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def _generate_pointcloud(self, rgb, depth):\n",
    "        h, w = depth.shape\n",
    "        fx, fy = 0.8*w, 0.8*h  # Simplified focal length\n",
    "\n",
    "        yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n",
    "        z = depth * 100  # Scale factor\n",
    "        x = (xx - w/2) * z / fx\n",
    "        y = (yy - h/2) * z / fy\n",
    "\n",
    "        points = np.vstack((x.ravel(), y.ravel(), z.ravel())).T\n",
    "        colors = rgb.reshape(-1, 3)/255.0\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        return pcd\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        # Preprocess frame\n",
    "        inputs = self.image_processor(images=[frame], return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        # Depth prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.depth_model(**inputs)\n",
    "            depth = outputs.predicted_depth.squeeze().cpu().numpy()\n",
    "\n",
    "        # Generate point cloud\n",
    "        pointcloud = self._generate_pointcloud(frame, depth)\n",
    "        return pointcloud\n",
    "\n",
    "# Function to align and merge point clouds\n",
    "def align_and_merge_pointclouds(pointclouds):\n",
    "    pcd_combined = pointclouds[0]\n",
    "    \n",
    "    for i in range(1, len(pointclouds)):\n",
    "        # Perform point-to-point ICP registration\n",
    "        icp_result = o3d.pipelines.registration.registration_icp(\n",
    "            pointclouds[i], pcd_combined, max_correspondence_distance=0.02,\n",
    "            estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "        )\n",
    "        # Transform the point cloud and merge it\n",
    "        pointclouds[i].transform(icp_result.transformation)\n",
    "        pcd_combined += pointclouds[i]\n",
    "    \n",
    "    # Downsample the merged point cloud\n",
    "    pcd_combined = pcd_combined.voxel_down_sample(voxel_size=0.01)\n",
    "    return pcd_combined\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize components\n",
    "    converter = VideoToTwinConverter(batch_size=32)\n",
    "\n",
    "    # Open the video file (use 0 for live camera feed)\n",
    "    video_path = '/path/to/your/video.mp4'  # Update this path to your video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frames = []\n",
    "    image_folder = './datafiles/custom/JPEGImages/640p/custom'\n",
    "    workspace_folder = './datafiles/custom/triangulation'\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    os.makedirs(workspace_folder, exist_ok=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    pointclouds = []\n",
    "    frame_skip = 5  # Process every 5th frame to reduce load\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_count % frame_skip == 0:\n",
    "                # Downsample the frame to reduce computational load\n",
    "                frame = cv2.resize(frame, (640, 480))\n",
    "                frames.append(frame)\n",
    "                frame_path = os.path.join(image_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                \n",
    "                # Process frame asynchronously\n",
    "                future = executor.submit(converter.process_frame, frame)\n",
    "                pointclouds.append(future)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "            # Monitor system and GPU memory usage\n",
    "            system_memory = psutil.virtual_memory()\n",
    "            gpu_memory = torch.cuda.memory_allocated()\n",
    "            print(f\"System Memory Usage: {system_memory.percent}%\")\n",
    "            print(f\"GPU Memory Usage: {gpu_memory / (1024 ** 2)} MB\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Wait for all point cloud processing to complete\n",
    "    pointclouds = [future.result() for future in pointclouds]\n",
    "\n",
    "    # Run PyCOLMAP to estimate camera pose and intrinsic parameters\n",
    "    run_pycolmap(image_folder, workspace_folder)\n",
    "\n",
    "    # Align and merge point clouds\n",
    "    pcd_combined = align_and_merge_pointclouds(pointclouds)\n",
    "\n",
    "    # Save the final 3D model\n",
    "    o3d.io.write_point_cloud(\"final_3d_model.ply\", pcd_combined)\n",
    "\n",
    "    # Visualize the final 3D model\n",
    "    o3d.visualization.draw_geometries([pcd_combined])\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total processing time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
